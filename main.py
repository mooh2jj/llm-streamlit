import os
# protobuf í˜¸í™˜ì„±ì„ ìœ„í•œ í™˜ê²½ë³€ìˆ˜ ì„¤ì • (ë‹¤ë¥¸ ëª¨ë“  importë³´ë‹¤ ë¨¼ì €!)
os.environ["PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION"] = "python"

try:
    __import__('pysqlite3')
    import sys
    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')
    print("<<<<< sqlite3 patched with pysqlite3 >>>>>")
except ImportError:
    # pysqlite3ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ sqlite3 ì‚¬ìš©
    print("<<<<< using default sqlite3 >>>>>")

print("<<<<< app.app.py IS BEING LOADED (sqlite3 patched with pysqlite3) >>>>>") # íŒ¨ì¹˜ ë‚´ìš© ëª…ì‹œ

import streamlit as st
import tempfile
from dotenv import load_dotenv
from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_openai import ChatOpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain.callbacks.base import BaseCallbackHandler
from langchain.schema import LLMResult
from typing import Dict, List, Any
import time
import uuid
import subprocess

from streamlit_extras.buy_me_a_coffee import button

button(username="ehtjd33e", floating=True, width=221)

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

st.set_page_config(page_title="ë²•ë¥ ê°€ ì±—ë´‡", page_icon=":books:", layout="wide")

st.title("ğŸ“š ë²•ë¥ ê°€ ì±—ë´‡")
st.caption("PDF ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì—¬ ë²•ë¥  ê´€ë ¨ ì§ˆë¬¸ì— ë‹µë³€ë°›ìœ¼ì„¸ìš”")

# OpenAI API í‚¤ ë¡œë“œ
openai_api_key = os.getenv("OPENAI_API_KEY")

# ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ ì½œë°± í•¸ë“¤ëŸ¬
class StreamlitCallbackHandler(BaseCallbackHandler):
    def __init__(self, container):
        self.container = container
        self.text = ""
        
    def on_llm_new_token(self, token: str, **kwargs) -> None:
        self.text += token
        self.container.markdown(self.text + "â–‹")  # ì»¤ì„œ íš¨ê³¼
        time.sleep(0.01)  # ìì—°ìŠ¤ëŸ¬ìš´ íƒ€ì´í•‘ íš¨ê³¼

    def on_llm_end(self, response: LLMResult, **kwargs) -> None:
        self.container.markdown(self.text)  # ìµœì¢… í…ìŠ¤íŠ¸ (ì»¤ì„œ ì œê±°)

# ì‚¬ì´ë“œë°”
with st.sidebar:
    st.header("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
    
    # PDF íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader(
        "PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
        type=["pdf"],
        help="ë²•ë¥  ë¬¸ì„œë‚˜ ê´€ë ¨ ìë£Œë¥¼ PDF í˜•íƒœë¡œ ì—…ë¡œë“œí•˜ì„¸ìš”"
    )
    
    st.divider()
    
    st.header("âš™ï¸ ì„¤ì •")
    if not openai_api_key:
        st.error("âš ï¸ .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”!")
        st.info("ğŸ“ .env íŒŒì¼ ì˜ˆì‹œ:\nOPENAI_API_KEY=your_api_key_here")
    else:
        st.success("âœ… OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    if uploaded_file:
        st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œë¨: {uploaded_file.name}")
        st.info(f"ğŸ“„ íŒŒì¼ í¬ê¸°: {uploaded_file.size / 1024:.1f} KB")

# ì•ˆì „í•œ ChromaDB ì‚­ì œ í•¨ìˆ˜ (ê°œì„ ëœ ë²„ì „)
def safe_delete_chromadb(max_retries=3, delay=1):
    """ChromaDB í´ë”ë¥¼ ì•ˆì „í•˜ê²Œ ì‚­ì œí•©ë‹ˆë‹¤."""
    import shutil
    import time
    import gc
    
    # ë¨¼ì € vectorstore ê°ì²´ í•´ì œ ë° ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
    if 'vectorstore' in st.session_state:
        st.session_state.vectorstore = None
    gc.collect()  # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ê°•ì œ ì‹¤í–‰
    
    chroma_dir = "./chroma_db"
    if not os.path.exists(chroma_dir):
        return True
    
    # ë¨¼ì € ì´ë¦„ ë³€ê²½ ì‹œë„ (Windowsì—ì„œ ë” ì•ˆì „í•¨)
    temp_name = f"./chroma_db_deleted_{uuid.uuid4().hex[:8]}"
    
    try:
        # í´ë” ì´ë¦„ ë³€ê²½ (ì¼ë°˜ì ìœ¼ë¡œ ì‚­ì œë³´ë‹¤ ë¹ ë¦„)
        os.rename(chroma_dir, temp_name)
        print(f"ChromaDB ë””ë ‰í† ë¦¬ ì´ë¦„ ë³€ê²½: {chroma_dir} -> {temp_name}")
        
        # ì´ë¦„ ë³€ê²½ í›„ ì‚­ì œ ì‹œë„
        for attempt in range(max_retries):
            try:
                time.sleep(delay)
                shutil.rmtree(temp_name)
                print(f"ChromaDB ë””ë ‰í† ë¦¬ ì‚­ì œ ì„±ê³µ: {temp_name}")
                return True
            except Exception as e:
                print(f"ì‚­ì œ ì‹œë„ {attempt + 1}/{max_retries} ì‹¤íŒ¨: {str(e)}")
                if attempt < max_retries - 1:
                    delay *= 2
        
        # ì‚­ì œ ì‹¤íŒ¨ ì‹œ ë‚˜ì¤‘ì— ì •ë¦¬í•˜ë„ë¡ ë‚¨ê²¨ë‘ 
        print(f"ChromaDB ë””ë ‰í† ë¦¬ ì‚­ì œ ì‹¤íŒ¨, ë‚˜ì¤‘ì— ì •ë¦¬ë¨: {temp_name}")
        return True  # ì´ë¦„ ë³€ê²½ì€ ì„±ê³µí–ˆìœ¼ë¯€ë¡œ True ë°˜í™˜
        
    except Exception as e:
        print(f"ChromaDB ë””ë ‰í† ë¦¬ ì´ë¦„ ë³€ê²½ ì‹¤íŒ¨: {str(e)}")
        return False

# ChromaDB ì •ë¦¬ í•¨ìˆ˜ (ê°œì„ ëœ ë²„ì „)
def cleanup_chromadb():
    """ê¸°ì¡´ ChromaDB í´ë”ë“¤ì„ ì •ë¦¬í•©ë‹ˆë‹¤."""
    import glob
    import shutil
    import time
    
    # ëª¨ë“  ChromaDB ê´€ë ¨ í´ë” ì°¾ê¸° (ì‚­ì œ ì˜ˆì • í´ë” í¬í•¨)
    chroma_dirs = glob.glob("./chroma_db*")
    
    for dir_path in chroma_dirs:
        try:
            # ì•½ê°„ì˜ ì§€ì—° í›„ ì‚­ì œ
            time.sleep(0.5)
            shutil.rmtree(dir_path)
            print(f"ì •ë¦¬ë¨: {dir_path}")
        except Exception as e:
            print(f"ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ({dir_path}): {str(e)}")
            # ì‚­ì œ ì‹¤íŒ¨í•œ í´ë”ëŠ” ë‹¤ìŒì— ë‹¤ì‹œ ì‹œë„

# ê°•ì œ ChromaDB ì •ë¦¬ í•¨ìˆ˜ (Windows ì „ìš©)
def force_cleanup_chromadb():
    """Windowsì—ì„œ ChromaDBë¥¼ ê°•ì œë¡œ ì •ë¦¬í•©ë‹ˆë‹¤."""
    import subprocess
    import glob
    import time
    
    chroma_dirs = glob.glob("./chroma_db*")
    
    for dir_path in chroma_dirs:
        try:
            # Windowsì˜ ê²½ìš° í•¸ë“¤ì„ ê°€ì§„ í”„ë¡œì„¸ìŠ¤ í™•ì¸ ë° ì •ë¦¬ ì‹œë„
            if os.name == 'nt':  # Windows
                try:
                    # robocopyë¥¼ ì‚¬ìš©í•œ ë¹ˆ í´ë”ë¡œ ë®ì–´ì“°ê¸° (Windows ì „ìš© íŠ¸ë¦­)
                    empty_dir = "./temp_empty_dir"
                    os.makedirs(empty_dir, exist_ok=True)
                    
                    # robocopyë¡œ ë¹ˆ í´ë” ë‚´ìš©ì„ ëŒ€ìƒ í´ë”ì— ë¯¸ëŸ¬ë§ (íš¨ê³¼ì ìœ¼ë¡œ ì‚­ì œ)
                    subprocess.run([
                        "robocopy", empty_dir, dir_path, "/MIR", "/NFL", "/NDL", "/NJH", "/NJS"
                    ], capture_output=True, check=False)
                    
                    # ë¹ˆ í´ë”ë“¤ ì‚­ì œ
                    os.rmdir(empty_dir)
                    os.rmdir(dir_path)
                    print(f"ê°•ì œ ì •ë¦¬ ì„±ê³µ: {dir_path}")
                    
                except Exception as e:
                    print(f"ê°•ì œ ì •ë¦¬ ì‹¤íŒ¨ ({dir_path}): {str(e)}")
            else:
                # Unix ê³„ì—´ ì‹œìŠ¤í…œì—ì„œëŠ” ì¼ë°˜ ì‚­ì œ
                import shutil
                shutil.rmtree(dir_path)
                print(f"ì •ë¦¬ë¨: {dir_path}")
                
        except Exception as e:
            print(f"ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ ({dir_path}): {str(e)}")

# ì•± ì‹œì‘ ì‹œ ChromaDB ì •ë¦¬ (ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ì „ì—)
if 'app_initialized' not in st.session_state:
    # ì¼ë°˜ ì •ë¦¬ ì‹œë„
    cleanup_chromadb()
    
    # Windowsì—ì„œ ì—¬ì „íˆ ë‚¨ì•„ìˆëŠ” í´ë”ê°€ ìˆë‹¤ë©´ ê°•ì œ ì •ë¦¬ ì‹œë„
    if os.name == 'nt':  # Windows
        import glob
        remaining_dirs = glob.glob("./chroma_db*")
        if remaining_dirs:
            print("Windowsì—ì„œ ê°•ì œ ì •ë¦¬ ì‹œë„...")
            force_cleanup_chromadb()
    
    st.session_state.app_initialized = True

# RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ë”ìš± ê°œì„ ëœ ë²„ì „)
@st.cache_resource
def initialize_rag_system(file_path):
    """RAG ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
    try:
        # PDF ë¬¸ì„œ ë¡œë”©
        loader = PyPDFLoader(file_path)
        documents = loader.load()
        
        # í…ìŠ¤íŠ¸ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        splits = text_splitter.split_documents(documents)
        
        # ì„ë² ë”© ëª¨ë¸ ì„¤ì • (í•œêµ­ì–´ ì§€ì›)
        embeddings = OpenAIEmbeddings(model="text-embedding-3-large")
        
        # ê³ ìœ í•œ ChromaDB ë””ë ‰í† ë¦¬ ì‚¬ìš© (ì¶©ëŒ ë°©ì§€)
        import time
        import uuid
        
        # íƒ€ì„ìŠ¤íƒ¬í”„ì™€ ëœë¤ IDë¡œ ê³ ìœ í•œ ë””ë ‰í† ë¦¬ëª… ìƒì„±
        chroma_dir = f"./chroma_db_{int(time.time())}_{uuid.uuid4().hex[:8]}"
        
        # ê¸°ì¡´ chroma_db í´ë”ê°€ ìˆë‹¤ë©´ ì´ë¦„ ë³€ê²½ìœ¼ë¡œ ì²˜ë¦¬
        old_chroma_dir = "./chroma_db"
        if os.path.exists(old_chroma_dir):
            try:
                # ì´ë¦„ ë³€ê²½ (ì‚­ì œë³´ë‹¤ ì•ˆì „)
                temp_name = f"./chroma_db_old_{uuid.uuid4().hex[:8]}"
                os.rename(old_chroma_dir, temp_name)
                print(f"ê¸°ì¡´ ChromaDB ë””ë ‰í† ë¦¬ ì´ë¦„ ë³€ê²½: {old_chroma_dir} -> {temp_name}")
            except Exception as e:
                print(f"ê¸°ì¡´ ChromaDB ë””ë ‰í† ë¦¬ ì´ë¦„ ë³€ê²½ ì‹¤íŒ¨: {str(e)}")

        # ìƒˆë¡œìš´ ChromaDB ë²¡í„° ì €ì¥ì†Œ ìƒì„±
        vectorstore = Chroma.from_documents(
            documents=splits,
            embedding=embeddings,
            persist_directory=chroma_dir
        )
        
        return vectorstore
    except Exception as e:
        st.error(f"RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

# ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
def save_uploaded_file(uploaded_file):
    """ì—…ë¡œë“œëœ íŒŒì¼ì„ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.getvalue())
            return tmp_file.name
    except Exception as e:
        st.error(f"íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

# RAG ì§ˆì˜ì‘ë‹µ í•¨ìˆ˜ (ìŠ¤íŠ¸ë¦¬ë° ë²„ì „)
def get_rag_response_streaming(question, vectorstore, api_key, container):
    """RAGë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤ (ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹)."""
    try:
        # ìŠ¤íŠ¸ë¦¬ë° ì½œë°± í•¸ë“¤ëŸ¬ ìƒì„±
        callback_handler = StreamlitCallbackHandler(container)
        
        # LLM ì„¤ì • (ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”)
        llm = ChatOpenAI(
            openai_api_key=api_key,
            model_name="gpt-4o-mini",
            temperature=0,
            streaming=True,
            callbacks=[callback_handler]
        )
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
        prompt_template = """
        ë‹¹ì‹ ì€ ë¬¸ì„œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”.
        ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³ , ëª¨ë¥¼ ê²½ìš° ì†”ì§íˆ ë§ì”€í•´ì£¼ì„¸ìš”.
        
        ë¬¸ì„œ ë‚´ìš©:
        {context}
        
        ì§ˆë¬¸: {question}
        
        ë‹µë³€:
        """
        
        PROMPT = PromptTemplate(
            template=prompt_template,
            input_variables=["context", "question"]
        )
        
        # RetrievalQA ì²´ì¸ ìƒì„±
        qa_chain = RetrievalQA.from_chain_type(
            llm=llm,
            chain_type="stuff",
            retriever=vectorstore.as_retriever(search_kwargs={"k": 3}),
            chain_type_kwargs={"prompt": PROMPT}
        )
        
        # ì§ˆì˜ì‘ë‹µ ì‹¤í–‰
        response = qa_chain.invoke({"query": question})
        return callback_handler.text  # ìŠ¤íŠ¸ë¦¬ë°ëœ ì „ì²´ í…ìŠ¤íŠ¸ ë°˜í™˜
        
    except Exception as e:
        error_msg = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        container.error(error_msg)
        return error_msg

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'messages' not in st.session_state:
    st.session_state.messages = []

if 'vectorstore' not in st.session_state:
    st.session_state.vectorstore = None

if 'current_file' not in st.session_state:
    st.session_state.current_file = None

# íŒŒì¼ ì—…ë¡œë“œ ì²˜ë¦¬
if uploaded_file:
    # ìƒˆ íŒŒì¼ì´ ì—…ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
    if st.session_state.current_file != uploaded_file.name:
        st.session_state.current_file = uploaded_file.name
        st.session_state.vectorstore = None  # ê¸°ì¡´ ë²¡í„° ìŠ¤í† ì–´ ì´ˆê¸°í™”
        st.session_state.messages = []  # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
        
        # íŒŒì¼ ì €ì¥ ë° RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        with st.spinner("ğŸ“„ PDF ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ì„ë² ë”©í•˜ê³  ìˆìŠµë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”!"):
            temp_file_path = save_uploaded_file(uploaded_file)
            if temp_file_path:
                st.session_state.vectorstore = initialize_rag_system(temp_file_path)
                # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                os.unlink(temp_file_path)
                
                if st.session_state.vectorstore:
                    st.success("âœ… ë¬¸ì„œê°€ ì„±ê³µì ìœ¼ë¡œ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤!")
                else:
                    st.error("âŒ ë¬¸ì„œ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
else:
    # íŒŒì¼ì´ ì‚­ì œëœ ê²½ìš° ì²˜ë¦¬
    if st.session_state.current_file is not None:
        # ì•ˆì „í•œ ChromaDB í´ë” ì‚­ì œ
        with st.spinner("ğŸ—‘ï¸ ê¸°ì¡´ ë¬¸ì„œ ë°ì´í„°ë¥¼ ì •ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            success = safe_delete_chromadb()
            if success:
                st.info("ğŸ—‘ï¸ ê¸°ì¡´ ë¬¸ì„œ ë°ì´í„°ê°€ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                st.warning("âš ï¸ ë°ì´í„° ì •ë¦¬ê°€ ì§€ì—°ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ì•± ì¬ì‹œì‘ ì‹œ ìë™ìœ¼ë¡œ ì •ë¦¬ë©ë‹ˆë‹¤.")
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        st.session_state.current_file = None
        st.session_state.vectorstore = None
        st.session_state.messages = []

# íŒŒì¼ì´ ì—…ë¡œë“œë˜ì§€ ì•Šì•˜ì„ ë•Œ ì•ˆë‚´
if not uploaded_file:
    st.info("ğŸ“ ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!")
    st.markdown("""
    ### ğŸ“‹ ì‚¬ìš© ë°©ë²•
    1. **íŒŒì¼ ì—…ë¡œë“œ**: ì‚¬ì´ë“œë°”ì—ì„œ PDF íŒŒì¼ ì—…ë¡œë“œ
    2. **ë¬¸ì„œ ë¶„ì„**: ì—…ë¡œë“œëœ ë¬¸ì„œê°€ ìë™ìœ¼ë¡œ ë¶„ì„ë©ë‹ˆë‹¤
    3. **ì§ˆë¬¸í•˜ê¸°**: ë¬¸ì„œ ë‚´ìš©ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”
    
    ### ğŸ“„ ì§€ì› íŒŒì¼ í˜•ì‹
    - PDF íŒŒì¼ë§Œ ì§€ì›ë©ë‹ˆë‹¤
    - í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ PDF íŒŒì¼ì´ì–´ì•¼ í•©ë‹ˆë‹¤
    """)
else:
    # ê¸°ì¡´ ë©”ì‹œì§€ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if user_question := st.chat_input(placeholder="ì—…ë¡œë“œëœ ë¬¸ì„œì— ëŒ€í•´ ì§ˆë¬¸í•´ì£¼ì„¸ìš”... ğŸ’¬"):
        # API í‚¤ í™•ì¸
        if not openai_api_key:
            st.error("OpenAI API í‚¤ë¥¼ ë¨¼ì € ì„¤ì •í•´ì£¼ì„¸ìš”! .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
        elif st.session_state.vectorstore is None:
            st.error("ë¬¸ì„œ ë¶„ì„ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        else:
            # ì‚¬ìš©ì ì§ˆë¬¸ í‘œì‹œ
            with st.chat_message("user"):
                st.markdown(user_question)
            st.session_state.messages.append({"role": "user", "content": user_question})

            # AI ë‹µë³€ ìƒì„± ë° ìŠ¤íŠ¸ë¦¬ë° í‘œì‹œ
            with st.chat_message("assistant"):
                # ìŠ¤íŠ¸ë¦¬ë°ì„ ìœ„í•œ ë¹ˆ ì»¨í…Œì´ë„ˆ ìƒì„±
                message_container = st.empty()
                
                # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë‹µë³€ ìƒì„±
                ai_response = get_rag_response_streaming(
                    user_question, 
                    st.session_state.vectorstore, 
                    openai_api_key,
                    message_container
                )
                
            st.session_state.messages.append({"role": "assistant", "content": ai_response})

# í•˜ë‹¨ì— ì‚¬ìš© íŒ ì¶”ê°€
if uploaded_file:
    st.divider()
    with st.expander("ğŸ’¡ ì‚¬ìš© íŒ"):
        st.markdown(f"""
        **í˜„ì¬ ë¶„ì„ ì¤‘ì¸ íŒŒì¼: {uploaded_file.name}**
        
        **ì´ ì±—ë´‡ì€ ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜ìš”?**
        - ğŸ“„ ì—…ë¡œë“œëœ PDF ë¬¸ì„œì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤
        - ğŸ” ê´€ë ¨ ì •ë³´ë¥¼ ê²€ìƒ‰í•˜ì—¬ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤
        - âš¡ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ë‹µë³€ì´ ìƒì„±ë©ë‹ˆë‹¤
        
        **ë” ë‚˜ì€ ë‹µë³€ì„ ìœ„í•œ íŒ:**
        - êµ¬ì²´ì ì´ê³  ëª…í™•í•œ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”
        - ë¬¸ì„œì˜ íŠ¹ì • ë¶€ë¶„ì— ëŒ€í•´ ì§ˆë¬¸í•´ë³´ì„¸ìš”
        - ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì†”ì§íˆ "ëª¨ë¥¸ë‹¤"ê³  ë‹µë³€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
        """)

    # ë””ë²„ê¹…ìš© (ê°œë°œ í™˜ê²½ì—ì„œë§Œ)
    if st.checkbox("ğŸ”§ ë””ë²„ê·¸ ëª¨ë“œ"):
        st.json({"ë©”ì‹œì§€ ê°œìˆ˜": len(st.session_state.messages)})
        with st.expander("ì „ì²´ ëŒ€í™” ë‚´ì—­"):
            st.json(st.session_state.messages)